{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51dbf63b-1993-458a-ab3e-822881ec5df3",
   "metadata": {},
   "source": [
    "# LSML1 SGA\n",
    "\n",
    "> Large Scale Machine Learning 1 (Spring23)\n",
    "\n",
    "> Sergey Terskov"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241985e7-6e4d-46e7-a9cd-2f5ff2a8ec8c",
   "metadata": {},
   "source": [
    "# Solution 1. Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eff189f4-a765-46d2-93d4-d2c35184c9fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-30 20:07:18,501 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial dataset example:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+------------+----------+----------+\n",
      "|user_id|session_id|  event_type|event_page| timestamp|\n",
      "+-------+----------+------------+----------+----------+\n",
      "|    562|       507|        page|      main|1695584127|\n",
      "|    562|       507|       event|      main|1695584134|\n",
      "|    562|       507|       event|      main|1695584144|\n",
      "|    562|       507|       event|      main|1695584147|\n",
      "|    562|       507|wNaxLlerrorU|      main|1695584154|\n",
      "+-------+----------+------------+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Top 30 frequent routes:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|               route|count|\n",
      "+--------------------+-----+\n",
      "|                main| 5984|\n",
      "|        main-archive|  839|\n",
      "|         main-rabota|  804|\n",
      "|       main-internet|  687|\n",
      "|          main-bonus|  657|\n",
      "|           main-news|  594|\n",
      "|        main-tariffs|  511|\n",
      "|         main-online|  445|\n",
      "|          main-vklad|  408|\n",
      "| main-archive-rabota|  136|\n",
      "| main-rabota-archive|  134|\n",
      "|   main-rabota-bonus|  111|\n",
      "|  main-bonus-archive|  109|\n",
      "|    main-news-rabota|  108|\n",
      "|   main-bonus-rabota|  105|\n",
      "|main-internet-arc...|  104|\n",
      "|main-internet-rabota|  104|\n",
      "|   main-archive-news|  103|\n",
      "|    main-rabota-news|  103|\n",
      "|  main-archive-bonus|  100|\n",
      "|main-archive-inte...|  100|\n",
      "|   main-news-archive|   94|\n",
      "|main-rabota-internet|   92|\n",
      "|main-tariffs-inte...|   89|\n",
      "| main-internet-bonus|   85|\n",
      "|  main-internet-news|   81|\n",
      "|     main-news-bonus|   80|\n",
      "|  main-news-internet|   78|\n",
      "|main-archive-tariffs|   76|\n",
      "| main-archive-online|   76|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 225 ms, sys: 121 ms, total: 346 ms\n",
      "Wall time: 1min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#Initialize Spark\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession, functions as F\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "sc = SparkContext(appName=\"LSML1_SGA\")\n",
    "se = SparkSession(sc)\n",
    "\n",
    "# Read data from HDFS\n",
    "events_df = se.read.format(\"csv\") \\\n",
    "      .options(delimiter=\"\\t\", header=True) \\\n",
    "      .schema(\"user_id bigint, session_id bigint, event_type string, event_page string, timestamp bigint\") \\\n",
    "      .load(\"hdfs:///data//clickstream.csv\")\n",
    "\n",
    "print(\"Initial dataset example:\")\n",
    "events_df.show(5)\n",
    "\n",
    "events_df.createOrReplaceTempView(\"events\")\n",
    "\n",
    "# SQL-query for routes\n",
    "query = \"\"\"\n",
    "    WITH filtered_events AS (\n",
    "        SELECT user_id, session_id, event_page, \n",
    "               ROW_NUMBER() OVER (PARTITION BY user_id, session_id ORDER BY timestamp) as row_num,\n",
    "               SUM(CASE WHEN event_type LIKE '%error%' THEN 1 ELSE 0 END) OVER (PARTITION BY user_id, session_id) as has_error\n",
    "        FROM events\n",
    "        WHERE event_type = 'page'\n",
    "    ),\n",
    "    final_routes AS (\n",
    "        SELECT user_id, session_id,\n",
    "               COLLECT_LIST(event_page) AS route\n",
    "        FROM filtered_events\n",
    "        WHERE has_error = 0 OR row_num <= (SELECT MAX(row_num) FROM filtered_events fe WHERE fe.user_id = filtered_events.user_id AND fe.session_id = filtered_events.session_id AND fe.has_error > 0)\n",
    "        GROUP BY user_id, session_id\n",
    "    ),\n",
    "    route_counts AS (\n",
    "        SELECT CONCAT_WS('-', route) AS route, COUNT(*) AS count\n",
    "        FROM final_routes\n",
    "        GROUP BY route\n",
    "    )\n",
    "    SELECT route, count\n",
    "    FROM route_counts\n",
    "    ORDER BY count DESC\n",
    "    LIMIT 30\n",
    "\"\"\"\n",
    "\n",
    "# Execute SQL\n",
    "top_routes_df = se.sql(query)\n",
    "\n",
    "# Show result\n",
    "print(\"Top 30 frequent routes:\")\n",
    "top_routes_df.show(30)\n",
    "\n",
    "# Save to csv\n",
    "top_routes_df.toPandas().to_csv(\"solution_1_SQL.csv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc84cd3-436b-4556-8fe0-3361dd2f2ff1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
