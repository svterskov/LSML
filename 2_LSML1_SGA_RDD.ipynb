{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51dbf63b-1993-458a-ab3e-822881ec5df3",
   "metadata": {},
   "source": [
    "# LSML1 SGA\n",
    "\n",
    "> Large Scale Machine Learning 1 (Spring23)\n",
    "\n",
    "> Sergey Terskov"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241985e7-6e4d-46e7-a9cd-2f5ff2a8ec8c",
   "metadata": {},
   "source": [
    "# Solution 2. Spark RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eff189f4-a765-46d2-93d4-d2c35184c9fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-30 20:03:58,456 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial dataset example:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+------------+----------+----------+\n",
      "|user_id|session_id|  event_type|event_page| timestamp|\n",
      "+-------+----------+------------+----------+----------+\n",
      "|    562|       507|        page|      main|1695584127|\n",
      "|    562|       507|       event|      main|1695584134|\n",
      "|    562|       507|       event|      main|1695584144|\n",
      "|    562|       507|       event|      main|1695584147|\n",
      "|    562|       507|wNaxLlerrorU|      main|1695584154|\n",
      "+-------+----------+------------+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 30 frequent routes:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|               route|count|\n",
      "+--------------------+-----+\n",
      "|                main| 5984|\n",
      "|        main-archive|  837|\n",
      "|         main-rabota|  802|\n",
      "|       main-internet|  686|\n",
      "|          main-bonus|  656|\n",
      "|           main-news|  594|\n",
      "|        main-tariffs|  511|\n",
      "|         main-online|  445|\n",
      "|          main-vklad|  408|\n",
      "| main-archive-rabota|  136|\n",
      "| main-rabota-archive|  134|\n",
      "|   main-rabota-bonus|  111|\n",
      "|  main-bonus-archive|  109|\n",
      "|    main-news-rabota|  108|\n",
      "|   main-bonus-rabota|  105|\n",
      "|main-internet-arc...|  104|\n",
      "|main-internet-rabota|  104|\n",
      "|   main-archive-news|  103|\n",
      "|    main-rabota-news|  103|\n",
      "|  main-archive-bonus|  100|\n",
      "|main-archive-inte...|  100|\n",
      "|   main-news-archive|   94|\n",
      "|main-rabota-internet|   92|\n",
      "|main-tariffs-inte...|   89|\n",
      "| main-internet-bonus|   85|\n",
      "|  main-internet-news|   81|\n",
      "|     main-news-bonus|   80|\n",
      "|  main-news-internet|   78|\n",
      "|main-archive-tariffs|   76|\n",
      "| main-archive-online|   76|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 963 ms, sys: 392 ms, total: 1.36 s\n",
      "Wall time: 1min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#Initialize Spark\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession, functions as F\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "sc = SparkContext(appName=\"LSML1_SGA\")\n",
    "se = SparkSession(sc)\n",
    "\n",
    "# Read data from HDFS\n",
    "events_df = se.read.format(\"csv\") \\\n",
    "      .options(delimiter=\"\\t\", header=True) \\\n",
    "      .schema(\"user_id bigint, session_id bigint, event_type string, event_page string, timestamp bigint\") \\\n",
    "      .load(\"hdfs:///data//clickstream.csv\")\n",
    "\n",
    "print(\"Initial dataset example:\")\n",
    "events_df.show(5)\n",
    "\n",
    "events_rdd = events_df.rdd\n",
    "\n",
    "# Group users by sessions\n",
    "def process_events(events):\n",
    "    user_sessions = {}\n",
    "    \n",
    "    for user_id, session_id, event_type, event_page, _ in events:\n",
    "        \n",
    "        if (user_id, session_id) not in user_sessions:\n",
    "            user_sessions[(user_id, session_id)] = {'pages': [], 'has_error': False}\n",
    "        \n",
    "        if not user_sessions[(user_id, session_id)]['has_error'] and event_type == \"page\":\n",
    "            user_sessions[(user_id, session_id)]['pages'].append(event_page)\n",
    "\n",
    "    return user_sessions\n",
    "\n",
    "# Get users' sessions\n",
    "user_sessions = events_rdd.groupBy(lambda x: (x[0], x[1])) \\\n",
    "    .flatMap(lambda x: process_events(x[1]).items())\n",
    "\n",
    "# Count of routes\n",
    "def count_routes(user_sessions):\n",
    "    route_counts = {}\n",
    "    \n",
    "    for (user_id, session_id), session_info in user_sessions:\n",
    "\n",
    "        route_str = '-'.join(session_info['pages'])\n",
    "        route_counts[route_str] = route_counts.get(route_str, 0) + 1\n",
    "    \n",
    "    return route_counts.items()\n",
    "\n",
    "route_counts_rdd = user_sessions.flatMap(lambda x: count_routes([x]))\n",
    "\n",
    "# Get routes\n",
    "top_routes_df = se.createDataFrame(\n",
    "    data=route_counts_rdd.reduceByKey(lambda a, b: a + b).takeOrdered(30, key=lambda x: -x[1]),\n",
    "    schema = [\"route\",\"count\"]\n",
    ")\n",
    "\n",
    "# Show result\n",
    "print(\"Top 30 frequent routes:\")\n",
    "top_routes_df.show(30)\n",
    "\n",
    "# Save to csv\n",
    "top_routes_df.toPandas().to_csv(\"solution_2_RDD.csv\", sep=\"\\t\")\n",
    "\n",
    "#Stop Spark session\n",
    "se.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64114e8c-dbb3-46da-8b71-0fe8c521df51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
