{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51dbf63b-1993-458a-ab3e-822881ec5df3",
   "metadata": {},
   "source": [
    "# LSML1 SGA\n",
    "\n",
    "> Large Scale Machine Learning 1 (Spring23)\n",
    "\n",
    "> Sergey Terskov"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241985e7-6e4d-46e7-a9cd-2f5ff2a8ec8c",
   "metadata": {},
   "source": [
    "# Solution 2. Spark RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eff189f4-a765-46d2-93d4-d2c35184c9fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-30 20:34:09,400 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial dataset example:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+------------+----------+----------+\n",
      "|user_id|session_id|  event_type|event_page| timestamp|\n",
      "+-------+----------+------------+----------+----------+\n",
      "|    562|       507|        page|      main|1695584127|\n",
      "|    562|       507|       event|      main|1695584134|\n",
      "|    562|       507|       event|      main|1695584144|\n",
      "|    562|       507|       event|      main|1695584147|\n",
      "|    562|       507|wNaxLlerrorU|      main|1695584154|\n",
      "+-------+----------+------------+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|               route|count|\n",
      "+--------------------+-----+\n",
      "|                main| 8054|\n",
      "|        main-archive| 1098|\n",
      "|         main-rabota| 1034|\n",
      "|       main-internet|  881|\n",
      "|          main-bonus|  854|\n",
      "|           main-news|  760|\n",
      "|        main-tariffs|  670|\n",
      "|         main-online|  582|\n",
      "|          main-vklad|  509|\n",
      "| main-rabota-archive|  168|\n",
      "| main-archive-rabota|  167|\n",
      "|  main-bonus-archive|  140|\n",
      "|   main-rabota-bonus|  138|\n",
      "|    main-news-rabota|  134|\n",
      "|   main-bonus-rabota|  131|\n",
      "|main-internet-rabota|  130|\n",
      "|    main-rabota-news|  130|\n",
      "|main-archive-inte...|  129|\n",
      "|   main-archive-news|  127|\n",
      "|main-rabota-internet|  123|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "Top 30 frequent routes:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|               route|count|\n",
      "+--------------------+-----+\n",
      "|                main| 8060|\n",
      "|        main-archive| 1093|\n",
      "|         main-rabota| 1036|\n",
      "|       main-internet|  880|\n",
      "|          main-bonus|  858|\n",
      "|           main-news|  760|\n",
      "|        main-tariffs|  669|\n",
      "|         main-online|  585|\n",
      "|          main-vklad|  510|\n",
      "| main-archive-rabota|  168|\n",
      "| main-rabota-archive|  166|\n",
      "|  main-bonus-archive|  141|\n",
      "|   main-rabota-bonus|  136|\n",
      "|    main-news-rabota|  133|\n",
      "|   main-bonus-rabota|  132|\n",
      "|main-archive-inte...|  129|\n",
      "|    main-rabota-news|  128|\n",
      "|main-internet-rabota|  127|\n",
      "|   main-archive-news|  124|\n",
      "|main-internet-arc...|  123|\n",
      "|main-rabota-internet|  122|\n",
      "|  main-archive-bonus|  117|\n",
      "| main-internet-bonus|  114|\n",
      "|main-tariffs-inte...|  113|\n",
      "|   main-news-archive|  112|\n",
      "|  main-news-internet|  109|\n",
      "|main-tariffs-archive|  101|\n",
      "|main-archive-tariffs|  100|\n",
      "|  main-internet-news|   99|\n",
      "|           main-main|   96|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 145 ms, sys: 170 ms, total: 315 ms\n",
      "Wall time: 1min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#Initialize Spark\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession, functions as F\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "sc = SparkContext(appName=\"LSML1_SGA\")\n",
    "se = SparkSession(sc)\n",
    "\n",
    "# Read data from HDFS\n",
    "events_df = se.read.format(\"csv\") \\\n",
    "      .options(delimiter=\"\\t\", header=True) \\\n",
    "      .schema(\"user_id bigint, session_id bigint, event_type string, event_page string, timestamp bigint\") \\\n",
    "      .load(\"hdfs:///data//clickstream.csv\")\n",
    "\n",
    "print(\"Initial dataset example:\")\n",
    "events_df.show(5)\n",
    "\n",
    "# Create routes for sessions\n",
    "def create_route(session_events):\n",
    "    route = []\n",
    "\n",
    "    for event_type, event_page in session_events:\n",
    "        if \"error\" in event_type:\n",
    "            break\n",
    "            \n",
    "        route.append(event_page)\n",
    "\n",
    "    return \"-\".join(route)\n",
    "\n",
    "create_route_udf = F.udf(create_route, StringType())\n",
    "\n",
    "# Group events by sessions\n",
    "routes_df = events_df\\\n",
    "    .filter(events_df.event_type != \"event\")\\\n",
    "    .sort(events_df.timestamp.asc())\\\n",
    "    .groupBy(\"user_id\", \"session_id\")\\\n",
    "    .agg(F.collect_list(F.struct(\"event_type\", \"event_page\")).alias(\"events\"))\n",
    "\n",
    "# Convert sessions to routes \n",
    "routes_df = routes_df.withColumn(\"route\", create_route_udf(routes_df[\"events\"]))\n",
    "\n",
    "# Get the most frequent routes\n",
    "top_routes_df = routes_df.groupBy(\"route\").count().orderBy(\"count\", ascending=False).limit(30)\n",
    "\n",
    "# Show result\n",
    "top_routes_df.show()\n",
    "\n",
    "# Show result\n",
    "print(\"Top 30 frequent routes:\")\n",
    "top_routes_df.show(30)\n",
    "\n",
    "# Save to csv\n",
    "top_routes_df.toPandas().to_csv(\"solution_3_DF.csv\", sep=\"\\t\")\n",
    "\n",
    "#Stop Spark session\n",
    "se.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64114e8c-dbb3-46da-8b71-0fe8c521df51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
